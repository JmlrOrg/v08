{
    "abstract": "Bayesian networks in general, and continuous variable networks in\nparticular, have become increasingly popular in recent years, largely\ndue to advances in methods that facilitate automatic learning from\ndata. Yet, despite these advances, the key task of learning the\nstructure of such models remains a computationally intensive\nprocedure, which limits most applications to parameter learning. This\nproblem is even more acute when learning networks in the presence of\nmissing values or hidden variables, a scenario that is part of many\nreal-life problems. In this work we present a general method for\nspeeding structure search for continuous variable networks with common\nparametric distributions. We efficiently evaluate the approximate\nmerit of candidate structure modifications and apply time consuming\n(exact) computations only to the most promising ones, thereby\nachieving significant improvement in the running time of the search\nalgorithm. Our method also naturally and efficiently facilitates the\naddition of useful new hidden variables into the network structure, a\ntask that is typically considered both conceptually difficult and\ncomputationally prohibitive. We demonstrate our method on synthetic\nand real-life data sets, both for learning structure on fully and\npartially observable data, and for introducing new hidden variables\nduring structure search.",
    "authors": [
        "Gal Elidan",
        "Iftach Nachman",
        "Nir Friedman"
    ],
    "id": "elidan07a",
    "issue": 62,
    "pages": [
        1799,
        1833
    ],
    "title": "\"Ideal Parent'' Structure Learning for Continuous Variable Bayesian Networks",
    "volume": "8",
    "year": "2007"
}