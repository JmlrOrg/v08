{
    "abstract": "Gaussian kernels with flexible variances provide a\nrich family of Mercer kernels for learning algorithms. We show that\nthe union of the unit balls of reproducing kernel Hilbert spaces\ngenerated by Gaussian kernels with flexible variances is a uniform\nGlivenko-Cantelli (uGC) class. This result confirms a conjecture\nconcerning learnability of Gaussian kernels and verifies the uniform\nconvergence of many learning algorithms involving Gaussians with\nchanging variances. Rademacher averages and empirical covering\nnumbers are used to estimate sample errors of multi-kernel\nregularization schemes associated with general loss functions. It is\nthen shown that the regularization error associated with the least\nsquare loss and the Gaussian kernels can be greatly improved when\nflexible variances are allowed. Finally, for regularization schemes\ngenerated by Gaussian kernels with flexible variances we present\nexplicit learning rates for regression with least square loss and\nclassification with hinge loss.",
    "authors": [
        "Yiming Ying",
        "Ding-Xuan Zhou"
    ],
    "id": "ying07a",
    "issue": 9,
    "pages": [
        249,
        276
    ],
    "title": "Learnability of Gaussians with Flexible Variances",
    "volume": "8",
    "year": "2007"
}