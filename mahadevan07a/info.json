{
    "abstract": "This paper introduces a novel <i>spectral</i> framework for solving\nMarkov decision processes (MDPs) by jointly learning representations\nand optimal policies.  The major components of the framework described\nin this paper include: (i) A general scheme for constructing\nrepresentations or <i>basis functions</i> by diagonalizing symmetric\n<i>diffusion</i> operators (ii) A specific instantiation of this\napproach where global basis functions called <i>proto-value\nfunctions</i> (PVFs) are formed using the eigenvectors of the <i>graph\nLaplacian</i> on an undirected graph formed from state transitions\ninduced by the MDP (iii) A three-phased procedure called \n<i>representation policy iteration</i> comprising of a sample collection\nphase, a representation learning phase that constructs basis functions\nfrom samples, and a final parameter estimation phase that determines\nan (approximately) optimal policy within the (linear) subspace spanned\nby the (current) basis functions. (iv) A specific instantiation of the\nRPI framework using least-squares policy iteration (LSPI) as the\nparameter estimation method (v) Several strategies for scaling the\nproposed approach to large discrete and continuous state spaces,\nincluding the <i>Nystr{{\\\"o}}m</i> extension for out-of-sample\ninterpolation of eigenfunctions, and the use of <i>Kronecker sum\nfactorization</i> to construct compact eigenfunctions in product spaces\nsuch as factored MDPs (vi) Finally, a series of illustrative discrete\nand continuous control tasks, which both illustrate the concepts and\nprovide a benchmark for evaluating the proposed approach.  Many\nchallenges remain to be addressed in scaling the proposed framework to\nlarge MDPs, and several elaboration of the proposed framework are\nbriefly summarized at the end.",
    "authors": [
        "Sridhar Mahadevan",
        "Mauro Maggioni"
    ],
    "id": "mahadevan07a",
    "issue": 74,
    "pages": [
        2169,
        2231
    ],
    "title": "Proto-value Functions: A Laplacian Framework for Learning Representation and Control in Markov Decision Processes",
    "volume": "8",
    "year": "2007"
}