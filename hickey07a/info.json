{
    "abstract": "To provide good classification accuracy on unseen examples, a decision\ntree, learned by an algorithm such as ID3, must have sufficient\nstructure and also identify the correct majority class in each of its\nleaves. If there are inadequacies in respect of either of these, the\ntree will have a percentage classification rate below that of the\nmaximum possible for the domain, namely (100 - Bayes error rate). An\nerror decomposition is introduced which enables the relative\ncontributions of deficiencies in structure and in incorrect\ndetermination of majority class to be isolated and quantified. A\nsub-decomposition of majority class error permits separation of the\nsampling error at the leaves from the possible bias introduced by the\nattribute selection method of the induction algorithm. It is shown\nthat sampling error can extend to 25% when there are more than two\nclasses. Decompositions are obtained from experiments on several data\nsets. For ID3, the effect of selection bias is shown to vary from\nbeing statistically non-significant to being quite substantial, with\nthe latter appearing to be associated with a simple underlying model.",
    "authors": [
        "Ray J. Hickey"
    ],
    "id": "hickey07a",
    "issue": 60,
    "pages": [
        1747,
        1768
    ],
    "title": "Structure and Majority Classes in Decision Tree Learning",
    "volume": "8",
    "year": "2007"
}